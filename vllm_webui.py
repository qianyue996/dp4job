import gradio as gr
import matplotlib.pyplot as plt
from PIL import Image
import io
import json
from dotenv import load_dotenv
import base64
import numpy as np
import os
from langchain.tools import Tool
import pandas as pd
from openai import OpenAI
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from mcp_tools.rag_client import RAG_SEARCH
load_dotenv()

rag_client = RAG_SEARCH()

recommand_prompt = """ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„æ™ºèƒ½æ‹›è˜é¡¾é—®ã€‚
ç”¨æˆ·çš„æé—®æ˜¯ï¼šquery: {query}
ä½ å¯ä»¥å‚è€ƒçš„å²—ä½ä¿¡æ¯å¦‚ä¸‹ï¼š
reference: {reference}

è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š
é¦–å…ˆï¼Œæ ¹æ® query ç²¾å‡†ç­›é€‰åŒ¹é…çš„å²—ä½ï¼Œå¦‚æœ reference ä¸­æœ‰å®Œå…¨æˆ–é«˜åº¦ç›¸å…³çš„å²—ä½ï¼Œè¯·ä¼˜å…ˆæ¨èè¿™äº›å²—ä½ï¼Œå¹¶ç®€æ´è¯´æ˜æ¨èç†ç”±ã€‚
å¦‚æœæ²¡æœ‰åŒ¹é…çš„å²—ä½ï¼Œè¯·ä»¥çƒ­æƒ…å‹å¥½ã€æ¨é”€å¼çš„è¯­æ°”ï¼Œæ¨èå…¶å®ƒä½ è®¤ä¸ºåˆé€‚çš„å²—ä½ï¼Œå¼ºè°ƒå²—ä½çš„ä¼˜åŠ¿ã€æ½œåŠ›æˆ–é€‚é…åº¦ï¼Œè®©ç”¨æˆ·å¯¹è¿™äº›å²—ä½äº§ç”Ÿå…´è¶£ã€‚
è¾“å‡ºæ—¶è¯·å°½é‡è‡ªç„¶ã€æœ‰å¸å¼•åŠ›ï¼Œä¸è¦æœºæ¢°åˆ—å‡ºå²—ä½ï¼Œè€Œæ˜¯åƒä¸ç”¨æˆ·å¯¹è¯ä¸€æ ·ï¼Œæœ‰å¼•å¯¼æ€§å’Œè¯´æœåŠ›ã€‚
ä¿æŒå†…å®¹ç®€æ´æ˜äº†ï¼Œä½†ä¸å¤±äººæƒ…å‘³ã€‚
æœ€ç»ˆè¾“å‡ºè¯·ä»¥æ¨èè¯­å¥çš„å½¢å¼ç»™å‡ºï¼Œä¸éœ€è¦è§£é‡Šä½ çš„æ¨èé€»è¾‘ã€‚"""

tool = [
    {
        "type": "function",
        "function": {
            "name": "get_job_info",
            "description": "ä»æœ¬åœ°çŸ¥è¯†åº“è·å–å²—ä½æ‹›è˜ä¿¡æ¯ã€‚å¯ä»¥æ ¹æ®åœ°ç‚¹ã€èŒä½ã€ç»éªŒçº§åˆ«ã€æ‰€éœ€æŠ€èƒ½å’Œå…¬å¸åç§°è¿›è¡Œç­›é€‰ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "æ‹›è˜å²—ä½æ‰€åœ¨çš„åŸå¸‚æˆ–åœ°åŒºï¼Œä¾‹å¦‚ 'åŒ—äº¬', 'ä¸Šæµ·', 'è¿œç¨‹'",
                    },
                    "job_title": {
                        "type": "string",
                        "description": "å²—ä½çš„å…·ä½“åç§°æˆ–å…³é”®è¯ï¼Œä¾‹å¦‚ 'è½¯ä»¶å·¥ç¨‹å¸ˆ', 'æ•°æ®ç§‘å­¦å®¶', 'å‰ç«¯å¼€å‘'",
                    },
                    "experience_level": {
                        "type": "string",
                        "description": "å²—ä½æ‰€éœ€çš„ç»éªŒçº§åˆ«ï¼Œä¾‹å¦‚ 'åˆçº§', 'ä¸­çº§', 'é«˜çº§', 'èµ„æ·±'",
                        "enum": ["ä¸é™", "åˆçº§", "ä¸­çº§", "é«˜çº§", "èµ„æ·±", "å®ä¹ ç”Ÿ"]
                    },
                    "skills": {
                        "type": "array",
                        "description": "å²—ä½æ‰€éœ€çš„æ ¸å¿ƒæŠ€èƒ½åˆ—è¡¨ï¼Œä¾‹å¦‚ ['Python', 'SQL', 'æœºå™¨å­¦ä¹ ', 'Java']",
                        "items": {"type": "string"}
                    },
                    "company_name": {
                        "type": "string",
                        "description": "ç‰¹å®šå…¬å¸çš„åç§°ï¼Œä¾‹å¦‚ 'å­—èŠ‚è·³åŠ¨', 'è…¾è®¯', 'é˜¿é‡Œå·´å·´'",
                    },
                },
                "required": ["location"],
            },
        },
    }
]

llm = OpenAI(base_url=os.environ.get("OPENAI_BASE_URL"), api_key=os.environ.get("OPENAI_API_KEY"))

class ModelChat():
    def __init__(self):
        self.history = [] # for gradio
        self.messages = [] # for llm

    def __call__(self, query: str, history: list):
        history.append({"role": "user", "content": query})

        if len(self.messages) == 0:
            self.messages = history.copy()
        else:
            self.messages.append({"role": "user", "content": query})

        response = llm.chat.completions.create(
            model=os.environ.get("MODEL_NAME"),
            messages=self.messages,
            temperature=0.7,
            tools=tool,
            tool_choice="auto",
        ).choices[0]

        if response.message.content is not None:
            history.append({"role": "assistant", "content": response.message.content})
            self.messages.append({"role": "assistant", "content": response.message.content})

        if response.finish_reason == "tool_calls":
            tool_call = response.message.tool_calls[0]
            tool_name = tool_call.function.name
            tool_args = json.loads(tool_call.function.arguments)

            tool_result =  rag_client(" ".join([str(value) for value in tool_args.values()]))

            self.messages[-1] = {
                "role": "user",
                "content": recommand_prompt.format(
                    query = history[-1]['content'],
                    reference = tool_result
                )
            }
            
            response = llm.chat.completions.create(
                model=os.environ.get("MODEL_NAME"),
                messages=self.messages,
                temperature=0.7,
                tools=tool,
                tool_choice="none",
            ).choices[0]

            history.append({"role": "assistant", "content": response.message.content})
            self.messages.append({"role": "assistant", "content": response.message.content})

        return "", history

modelchat = ModelChat()

# é™æ€æ•°æ® - ç®€å†è§£æç»“æœ
static_resume_data = {
    "user_name": "å¼ ä¸‰",
    "user_education": "XXå¤§å­¦ è®¡ç®—æœºç§‘å­¦ ç¡•å£«",
    "user_experience": "3å¹´æ·±åº¦å­¦ä¹ å·¥ç¨‹å¸ˆç»éªŒï¼Œè´Ÿè´£æ¨¡å‹è®¾è®¡ä¸ä¼˜åŒ–ã€‚",
    "user_skills": "Python, æ·±åº¦å­¦ä¹ , è‡ªç„¶è¯­è¨€å¤„ç†, PyTorch, Transformer, æœºå™¨å­¦ä¹ , Git, SQL"
}

# é™æ€æ•°æ® - èŒä½æ¨èåˆ—è¡¨
static_jobs_data = {
    "èŒä½åç§°": [
        "é«˜çº§AIç®—æ³•å·¥ç¨‹å¸ˆ", "è‡ªç„¶è¯­è¨€å¤„ç†ä¸“å®¶", "æ¨èç³»ç»Ÿå¼€å‘å·¥ç¨‹å¸ˆ", "æ•°æ®ç§‘å­¦å®¶", "æœºå™¨å­¦ä¹ ç ”ç©¶å‘˜"
    ],
    "å…¬å¸": [
        "å¤§å‚ç§‘æŠ€", "åˆ›æ–°æ™ºèƒ½", "æœªæ¥æ•°æ®", "æ•°æ™ºäº’è”", "å‰æ²¿AI"
    ],
    "åœ°ç‚¹": [
        "åŒ—äº¬", "ä¸Šæµ·", "æ·±åœ³", "æ­å·", "åŒ—äº¬"
    ],
    "è–ªèµ„ (K/æœˆ)": [
        "25-45", "30-50", "20-40", "28-48", "35-60"
    ],
    "åŒ¹é…åº¦": [
        0.92, 0.87, 0.85, 0.83, 0.80
    ],
    "èŒä½ID": [
        "J001", "J002", "J003", "J004", "J005"
    ]
}

# é™æ€æ•°æ® - æ¨èç†ç”±
static_reason = """
**é«˜çº§AIç®—æ³•å·¥ç¨‹å¸ˆ** (å¤§å‚ç§‘æŠ€)ï¼š

è¯¥èŒä½é«˜åº¦åŒ¹é…æ‚¨çš„**3å¹´æ·±åº¦å­¦ä¹ å·¥ç¨‹å¸ˆç»éªŒï¼Œè´Ÿè´£æ¨¡å‹è®¾è®¡ä¸ä¼˜åŒ–**ä»¥åŠç²¾é€šçš„**Python, æ·±åº¦å­¦ä¹ , è‡ªç„¶è¯­è¨€å¤„ç†, PyTorch**æŠ€èƒ½ã€‚æˆ‘ä»¬ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢åˆ°ï¼Œè¯¥èŒä½è¦æ±‚æ‰å®çš„**æ·±åº¦å­¦ä¹ **å’Œ**è‡ªç„¶è¯­è¨€å¤„ç†**èƒŒæ™¯ï¼Œä¸æ‚¨çš„æŠ€èƒ½æ ˆé«˜åº¦å»åˆã€‚æ­¤å¤–ï¼Œè¯¥èŒä½æ‰€åœ¨å…¬å¸åœ¨**äººå·¥æ™ºèƒ½**é¢†åŸŸå…·æœ‰é¢†å…ˆåœ°ä½ï¼Œä¸æ‚¨çš„èŒä¸šå‘å±•æ–¹å‘å¥‘åˆã€‚
"""

# é™æ€æ•°æ® - è¡Œä¸šæ´å¯Ÿ
static_industry_insight = """
### è¡Œä¸šæ´å¯Ÿï¼šé«˜çº§AIç®—æ³•å·¥ç¨‹å¸ˆé¢†åŸŸ

è¿‘æœŸ**ã€Š2025äººå·¥æ™ºèƒ½äººæ‰å‘å±•æŠ¥å‘Šã€‹**æŒ‡å‡ºï¼Œ**é«˜çº§AIç®—æ³•å·¥ç¨‹å¸ˆ**ç›¸å…³é¢†åŸŸæ­£å¤„äºé«˜é€Ÿå‘å±•æœŸï¼Œç‰¹åˆ«æ˜¯**å¤§æ¨¡å‹å¾®è°ƒä¸åº”ç”¨å¼€å‘**éœ€æ±‚æ¿€å¢ã€‚æ•°æ®æ˜¾ç¤ºï¼Œæœªæ¥ä¸‰å¹´è¯¥é¢†åŸŸäººæ‰ç¼ºå£é¢„è®¡è¾¾åˆ°**30%**ã€‚å»ºè®®æ‚¨è¿›ä¸€æ­¥å…³æ³¨**å¤šæ¨¡æ€å¤§æ¨¡å‹**å’Œ**AIå®‰å…¨**ä»¥å¢å¼ºç«äº‰åŠ›ã€‚

#### è–ªèµ„è¶‹åŠ¿
- ä¸€çº¿åŸå¸‚å¹³å‡å¹´è–ªï¼š70-120ä¸‡
- æ ¸å¿ƒæŠ€èƒ½æº¢ä»·ï¼šæ‹¥æœ‰Transformerã€å¤šæ¨¡æ€ç»éªŒè€…è–ªèµ„ä¸Šæµ®20-30%

#### çƒ­é—¨å…¬å¸
1. å¤§å‚ç§‘æŠ€ - ä¸“æ³¨äºé€šç”¨äººå·¥æ™ºèƒ½ç ”å‘
2. åˆ›æ–°æ™ºèƒ½ - å‚ç›´é¢†åŸŸå¤§æ¨¡å‹åº”ç”¨
3. æœªæ¥æ•°æ® - é‡‘èAIè§£å†³æ–¹æ¡ˆæä¾›å•†
"""

# ç”ŸæˆæŠ€èƒ½é›·è¾¾å›¾ï¼ˆé™æ€ï¼‰
def create_skill_radar_chart():
    user_skills = ["Python", "æ·±åº¦å­¦ä¹ ", "è‡ªç„¶è¯­è¨€å¤„ç†", "PyTorch", "Transformer", "æœºå™¨å­¦ä¹ "]
    job_title = "é«˜çº§AIç®—æ³•å·¥ç¨‹å¸ˆ"
    
    num_vars = len(user_skills)
    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()
    angles += angles[:1]

    # ç”¨æˆ·æŠ€èƒ½å¾—åˆ†
    user_values = [0.9, 0.85, 0.8, 0.75, 0.7, 0.85]
    user_values += user_values[:1]

    # èŒä½æ‰€éœ€æŠ€èƒ½å¾—åˆ†
    job_values = [0.8, 0.9, 0.7, 0.8, 0.9, 0.8]
    job_values += job_values[:1]

    fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(polar=True))
    ax.fill(angles, user_values, color='red', alpha=0.25, label='æ‚¨çš„æŠ€èƒ½ç†Ÿç»ƒåº¦')
    ax.plot(angles, user_values, color='red', linewidth=2)

    ax.fill(angles, job_values, color='blue', alpha=0.25, label=f'{job_title}æ‰€éœ€æŠ€èƒ½')
    ax.plot(angles, job_values, color='blue', linewidth=2)

    ax.set_theta_offset(np.pi / 2)
    ax.set_theta_direction(-1)
    ax.set_rlabel_position(0)
    ax.set_xticks(angles[:-1])
    ax.set_xticklabels(user_skills)
    ax.set_ylim(0, 1)
    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))
    ax.set_title(f'æŠ€èƒ½åŒ¹é…é›·è¾¾å›¾ - {job_title}', va='bottom')

    buf = io.BytesIO()
    plt.savefig(buf, format='png')
    buf.seek(0)
    img_str = base64.b64encode(buf.read()).decode('utf-8')
    plt.close(fig)
    return f"data:image/png;base64,{img_str}"

# ç”Ÿæˆé™æ€èŒä½æ¨èæ•°æ®æ¡†
def get_static_jobs_df():
    df = pd.DataFrame(static_jobs_data)
    return df

# ç”Ÿæˆé™æ€æŠ€èƒ½é›·è¾¾å›¾
def get_static_radar_chart():
    img_data = create_skill_radar_chart()
    buf = io.BytesIO(base64.b64decode(img_data.split(',')[1]))
    img = Image.open(buf)
    return img

# --- Gradio ç•Œé¢è®¾è®¡ ---

with gr.Blocks(theme=gr.themes.Soft(), title="RAGå°±ä¸šæ¨èç³»ç»Ÿ") as demo:
    gr.Markdown(
        """
        # ğŸš€ åŸºäºRAGçš„æ™ºèƒ½å°±ä¸šæ¨èç³»ç»Ÿ
        æœ¬ç³»ç»Ÿç»“åˆäº†**æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG)** æŠ€æœ¯ä¸æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œä¸ºæ‚¨æä¾›**ä¸ªæ€§åŒ–ã€å¯è§£é‡Š**çš„èŒä½æ¨èã€‚
        é€šè¿‡ä¸Šä¼ ç®€å†å’Œå¡«å†™æ±‚èŒåå¥½ï¼Œç³»ç»Ÿå°†ä»æµ·é‡çŸ¥è¯†åº“ä¸­æ£€ç´¢å¹¶ç”Ÿæˆæœ€é€‚åˆæ‚¨çš„èŒä½åŠåŒ¹é…ç†ç”±ã€‚
        """
    )
    
    # ç³»ç»ŸçŠ¶æ€æç¤º
    status_output = gr.Textbox(
        label="ç³»ç»ŸçŠ¶æ€",
        value="å·²åŠ è½½æ¼”ç¤ºæ•°æ®",
        interactive=False,
        show_copy_button=True,
        elem_id="status_box",
        lines=1
    )

    with gr.Tabs():
        with gr.TabItem("ç®€å†ä¸Šä¼ ä¸è§£æ"):
            with gr.Row():
                with gr.Column(scale=1):
                    resume_file = gr.File(label="ä¸Šä¼ æ‚¨çš„ç®€å† (PDF/TXT)", file_types=["pdf", "txt"])
                    parse_resume_btn = gr.Button("è§£æç®€å†", variant="primary")
                    
                with gr.Column(scale=2):
                    gr.Markdown("#### ç®€å†è§£æç»“æœ")
                    user_name = gr.Textbox(label="å§“å", value=static_resume_data["user_name"], interactive=False)
                    user_education = gr.Textbox(label="æ•™è‚²èƒŒæ™¯", value=static_resume_data["user_education"], interactive=False)
                    user_experience = gr.Textbox(label="å·¥ä½œç»éªŒ", value=static_resume_data["user_experience"], interactive=False)
                    user_skills = gr.Textbox(label="æŠ€èƒ½æ ‡ç­¾", value=static_resume_data["user_skills"], interactive=False)
            
            # æŒ‰é’®ç‚¹å‡»äº‹ä»¶ - ä»…æ›´æ–°çŠ¶æ€
            parse_resume_btn.click(
                fn=lambda: "ç®€å†è§£ææˆåŠŸï¼ï¼ˆæ¼”ç¤ºæ¨¡å¼ï¼‰",
                inputs=None,
                outputs=status_output
            )

        with gr.TabItem("æ±‚èŒåå¥½ä¸æ¨è"):
            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown("#### æ‚¨çš„æ±‚èŒåå¥½")
                    desired_job_title = gr.Textbox(label="æœŸæœ›èŒä½å…³é”®è¯", placeholder="ä¾‹å¦‚ï¼šAIå·¥ç¨‹å¸ˆ, NLPç ”ç©¶å‘˜", value="AIç®—æ³•å·¥ç¨‹å¸ˆ")
                    desired_location = gr.Dropdown(
                        ["åŒ—äº¬", "ä¸Šæµ·", "æ·±åœ³", "æ­å·", "å¹¿å·", "å…¨å›½"], 
                        label="æœŸæœ›å·¥ä½œåœ°ç‚¹", 
                        value="åŒ—äº¬"
                    )
                    desired_salary_min = gr.Slider(
                        minimum=5, maximum=100, step=1, value=20, label="æœŸæœ›æœˆè–ª (K) - æœ€å°å€¼"
                    )
                    desired_salary_max = gr.Slider(
                        minimum=5, maximum=100, step=1, value=40, label="æœŸæœ›æœˆè–ª (K) - æœ€å¤§å€¼"
                    )
                    
                    recommend_btn = gr.Button("è·å–ä¸ªæ€§åŒ–æ¨è", variant="primary")
                    
                with gr.Column(scale=2):
                    gr.Markdown("#### èŒä½æ¨èåˆ—è¡¨")
                    recommended_jobs_df = gr.DataFrame(
                        headers=["èŒä½åç§°", "å…¬å¸", "åœ°ç‚¹", "è–ªèµ„ (K/æœˆ)", "åŒ¹é…åº¦"],
                        datatype=["str", "str", "str", "str", "number"],
                        label="æ¨èèŒä½",
                        interactive=False
                    )
                    
            with gr.Row():
                with gr.Column():
                    gr.Markdown("#### æ¨èç†ç”± (é’ˆå¯¹ç¬¬ä¸€æ¡æ¨è)")
                    recommended_reason = gr.Markdown(static_reason)
                    
                with gr.Column():
                    gr.Markdown("#### æŠ€èƒ½åŒ¹é…åº¦åˆ†æ")
                    skill_radar_plot = gr.Image(label="æŠ€èƒ½é›·è¾¾å›¾", value=get_static_radar_chart())

            # æ¨èæŒ‰é’®ç‚¹å‡»äº‹ä»¶ - æ›´æ–°æ¨èç»“æœ
            recommend_btn.click(
                fn=lambda: (get_static_jobs_df(), static_reason, "æ¨èæˆåŠŸï¼ï¼ˆæ¼”ç¤ºæ¨¡å¼ï¼‰", get_static_radar_chart()),
                inputs=None,
                outputs=[recommended_jobs_df, recommended_reason, status_output, skill_radar_plot]
            )
            
            # å½“æ¨èåˆ—è¡¨è¢«ç‚¹å‡»æ—¶ï¼Œæ›´æ–°æ¨èç†ç”±å’ŒæŠ€èƒ½é›·è¾¾å›¾
            def update_selected_job_info(evt: gr.SelectData):
                if evt.index is not None:
                    # æ ¹æ®ç‚¹å‡»çš„è¡Œç´¢å¼•æ›´æ–°æ¨èç†ç”±å’Œé›·è¾¾å›¾
                    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œä»…å±•ç¤ºä¸åŒçš„èŒä½åç§°
                    job_title = static_jobs_data["èŒä½åç§°"][evt.index[0]]
                    new_reason = static_reason.replace("é«˜çº§AIç®—æ³•å·¥ç¨‹å¸ˆ", job_title)
                    return new_reason, get_static_radar_chart()
                return gr.No(), gr.No()

            recommended_jobs_df.select(
                fn=update_selected_job_info,
                outputs=[recommended_reason, skill_radar_plot]
            )

        with gr.TabItem("è¡Œä¸šæ´å¯Ÿ"):
            gr.Markdown("#### ä¸æ‚¨æœŸæœ›èŒä½ç›¸å…³çš„æœ€æ–°è¡Œä¸šæ´å¯Ÿä¸è¶‹åŠ¿åˆ†æ")
            industry_insight = gr.Markdown(static_industry_insight)
            
            # æ¨èæŒ‰é’®ç‚¹å‡»æ—¶ï¼Œæ›´æ–°è¡Œä¸šæ´å¯Ÿ
            recommend_btn.click(
                fn=lambda: static_industry_insight,
                inputs=None,
                outputs=industry_insight
            )

        with gr.TabItem("æ±‚èŒæ¨èç³»ç»Ÿ"):
            gr.Markdown("#### æŸ¥è¯¢æ‚¨é€‚åˆä»€ä¹ˆå·¥ä½œ")
            with gr.Column(scale=10):
                chatbot = gr.Chatbot(
                    label="èŠå¤©åŒºåŸŸ",
                    height=400,
                    type="messages",
                    value=[{"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæä¾›å²—ä½æ¨èçš„æ™ºèƒ½åŠ©æ‰‹ã€‚å½“ç”¨æˆ·è¯¢é—®æŸä¸ªå²—ä½æ—¶ï¼Œä½ é¦–å…ˆå°è¯•åŒ¹é…ä½ å·²çŸ¥çš„å²—ä½æ•°æ®ã€‚å¦‚æœä½ å‘ç°è‡ªå·±åº“ä¸­æ²¡æœ‰å…³äºç”¨æˆ·æ‰€æå²—ä½çš„å…·ä½“ä¿¡æ¯ï¼Œé‚£ä¹ˆè¯·ä»¥æ¨¡ç³Šã€æ¦‚æ‹¬çš„æ–¹å¼å›ç­”ï¼Œå¹¶ä¸»åŠ¨æ¨èä½ æ‰€äº†è§£çš„ä¸æ­¤é¢†åŸŸç›¸å…³çš„å…¶ä»–å²—ä½æ•°æ®ã€‚ä¾‹å¦‚ï¼Œå½“ç”¨æˆ·æŸ¥è¯¢ä¸€ä¸ªä½ æ²¡æœ‰ç›´æ¥è®°å½•çš„å²—ä½æ—¶ï¼Œä½ å¯ä»¥å›ç­”ï¼šâ€œå…³äºè¿™ä¸ªå²—ä½çš„ä¿¡æ¯æˆ‘è¿™é‡Œèµ„æ–™æ¯”è¾ƒæœ‰é™ï¼Œä¸è¿‡æˆ‘æ³¨æ„åˆ°åœ¨è¿™ä¸ªé¢†åŸŸæœ‰ä¸€äº›ç±»ä¼¼çš„èŒä½ï¼Œæ¯”å¦‚â€¦â€¦ä½ å¯ä»¥äº†è§£ä¸€ä¸‹è¿™äº›å²—ä½ã€‚â€è¯·åŠ¡å¿…æ³¨æ„ï¼Œå›ç­”æ—¶ä¿æŒè¯­æ°”å‹å¥½ä¸”å…·æœ‰å»ºè®¾æ€§ï¼Œå¸®åŠ©ç”¨æˆ·è·å¾—æ›´å¤šæ–¹å‘çš„ä¿¡æ¯ã€‚å½“ç”¨æˆ·é—®é¢˜è¶…å‡ºä½ çŸ¥è¯†èŒƒå›´æˆ–éœ€è¦æŸ¥è¯¢æœ€æ–°æ•°æ®æ—¶ï¼Œè¯·ä¸»åŠ¨è°ƒç”¨å·¥å…·æ£€ç´¢ç›¸å…³ä¿¡æ¯ï¼Œå¹¶ç”¨å·¥å…·è¿”å›çš„å†…å®¹ç”Ÿæˆå›ç­”ã€‚"}]
                )
                msg = gr.Textbox(label="è¾“å…¥æ¡†", placeholder="è¯·è¾“å…¥ä½ çš„é—®é¢˜...")
                with gr.Row():
                    submit = gr.Button("å‘é€")
                    clear = gr.ClearButton([msg, chatbot])
            
        # æ·»åŠ äº‹ä»¶å¤„ç†
        msg.submit(modelchat, [msg, chatbot], [msg, chatbot])
        submit.click(modelchat, [msg, chatbot], [msg, chatbot])

    # åº•éƒ¨ç‰ˆæƒä¿¡æ¯
    gr.Markdown(
        """
        ---
        Â© 2025 RAGå°±ä¸šæ¨èç³»ç»Ÿ. All rights reserved.
        """
    )

    # è®¾ç½®åˆå§‹æ•°æ®
    demo.load(
        fn=lambda: (
            get_static_jobs_df(),
            static_reason,
            get_static_radar_chart()
        ),
        inputs=None,
        outputs=[recommended_jobs_df, recommended_reason, skill_radar_plot]
    )

if __name__ == "__main__":
    demo.queue() # å¯ç”¨é˜Ÿåˆ—ï¼Œå¤„ç†å¹¶å‘è¯·æ±‚
    demo.launch(debug=True, inline=False, share=False, allowed_paths=["."]) # inline=Falseä¼šåœ¨æµè§ˆå™¨ä¸­æ‰“å¼€æ–°æ ‡ç­¾é¡µ

